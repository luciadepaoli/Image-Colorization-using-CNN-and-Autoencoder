{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image colorization using CNN - Fruits Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# For conversion\n",
    "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# For our model\n",
    "from torchvision import datasets, transforms\n",
    "# For utilities\n",
    "import patoolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XEuVMpT0NpiJ"
   },
   "outputs": [],
   "source": [
    "tr = 'images/train/'\n",
    "te = 'images/val/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to extract the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00007-a15475e3-9587-4bdc-a456-1ca04c341a2e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1624900779548,
    "id": "OQOU7KeHsgwU",
    "source_hash": "be8fe340",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aQXceYXzSOVx"
   },
   "outputs": [],
   "source": [
    "# Class BaseColor from Zhang's github repository\n",
    "class BaseColor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseColor, self).__init__()\n",
    "\n",
    "        self.l_cent = 50.\n",
    "        self.l_norm = 100.\n",
    "        self.ab_norm = 110.\n",
    "\n",
    "    def normalize_l(self, in_l):\n",
    "        return (in_l-self.l_cent)/self.l_norm\n",
    "\n",
    "    def unnormalize_l(self, in_l):\n",
    "        return in_l*self.l_norm + self.l_cent\n",
    "\n",
    "    def normalize_ab(self, in_ab):\n",
    "        return in_ab/self.ab_norm\n",
    "\n",
    "    def unnormalize_ab(self, in_ab):\n",
    "        return in_ab*self.ab_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "TXCf3tFuSJ4t"
   },
   "outputs": [],
   "source": [
    "class Colorization(BaseColor):\n",
    "    def __init__(self, norm_layer=nn.BatchNorm2d):\n",
    "        super(ECCVGenerator, self).__init__()\n",
    "\n",
    "        model1=[nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[norm_layer(64),]\n",
    "\n",
    "        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[norm_layer(128),]\n",
    "\n",
    "        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[norm_layer(256),]\n",
    "\n",
    "        model4 =[nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0, bias=True),]\n",
    "\n",
    "        self.model1 = nn.Sequential(*model1)\n",
    "        self.model2 = nn.Sequential(*model2)\n",
    "        self.model3 = nn.Sequential(*model3)\n",
    "        self.model4 = nn.Sequential(*model4)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.model_out = nn.Conv2d(256, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
    "        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "\n",
    "    def forward(self, input_l):\n",
    "        conv1 = self.model1(self.normalize_l(input_l))\n",
    "        conv2 = self.model2(conv1)\n",
    "        conv3 = self.model3(conv2)\n",
    "        conv4 = self.model4(conv3)\n",
    "        out_reg = self.model_out(self.softmax(conv4))\n",
    "\n",
    "        return self.unnormalize_ab(self.upsample4(out_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00011-d69cd05b-02d6-4b61-8a9c-08d1beee32a3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1624906504029,
    "id": "n0gtaysYsgwZ",
    "source_hash": "6854d511",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class used to transform images for the network\n",
    "class GrayscaleImageFolder(datasets.ImageFolder):\n",
    "  '''Custom images folder, which converts images to grayscale before loading'''\n",
    "  def __getitem__(self, index):\n",
    "    path, target = self.imgs[index]\n",
    "    img = self.loader(path)\n",
    "    if self.transform is not None:\n",
    "      img_original = self.transform(img)\n",
    "      img_original = np.asarray(img_original)\n",
    "      img_lab = rgb2lab(img_original)\n",
    "      img_lab = (img_lab + 128) / 255\n",
    "      img_ab = img_lab[:, :, 1:3]\n",
    "      img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n",
    "      img_original = rgb2gray(img_original)\n",
    "      img_original = torch.from_numpy(img_original).unsqueeze(0).float()\n",
    "    if self.target_transform is not None:\n",
    "      target = self.target_transform(target)\n",
    "    return img_original, img_ab, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00013-2df8711b-43f9-4d41-8355-9feb8a5bf5ef",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1624906505469,
    "id": "9Y0UarAisgwa",
    "source_hash": "e7772925",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function used to convert images from LAB color space to RGB in order to visualize the results\n",
    "def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n",
    "  '''Show/save rgb image from grayscale and ab channels\n",
    "     Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n",
    "  plt.clf() # clear matplotlib \n",
    "  color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels\n",
    "  color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128   \n",
    "  color_image = lab2rgb(color_image.astype(np.float64))\n",
    "  grayscale_input = grayscale_input.squeeze().numpy()\n",
    "  if save_path is not None and save_name is not None: \n",
    "    plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n",
    "    plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HycLl4PZG_Nt"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion, save_images, epoch):\n",
    "  epoch_loss = 0\n",
    "\n",
    "  # Evaluation mode\n",
    "  model.eval()\n",
    "  already_saved_images = False\n",
    "    \n",
    "  # Do not compute gradients\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for i, (input_gray, input_ab, target) in enumerate(val_loader):\n",
    "      if use_gpu: input_gray, input_ab, target = input_gray.to('cuda'), input_ab.to('cuda'), target.to('cuda')\n",
    "      # Make Predictions\n",
    "      output_ab = model(input_gray) # throw away class predictions\n",
    "      loss = criterion(output_ab, input_ab)\n",
    "      # Extract data from loss and accuracy\n",
    "      epoch_loss += loss.item()\n",
    "    \n",
    "      # Save images to file\n",
    "      if save_images and not already_saved_images:\n",
    "        already_saved_images = True\n",
    "        for j in range(len(output_ab)):\n",
    "          save_path = {'grayscale': 'outputs/gray/', 'colorized': 'outputs/color/'}\n",
    "          save_name = 'img-{}-epoch-{}.jpg'.format(i * val_loader.batch_size + j, epoch)\n",
    "          to_rgb(input_gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)\n",
    "\n",
    "  return epoch_loss/len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3dwlnrY7G_Nv"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "  epoch_loss = 0\n",
    "\n",
    "  # Train mode\n",
    "  model.train()\n",
    "\n",
    "  for i, (input_gray, input_ab, target) in enumerate(train_loader):\n",
    "    if use_gpu: input_gray, input_ab, target = input_gray.to('cuda'), input_ab.to('cuda'), target.to('cuda')\n",
    "    # Set gradients to zero\n",
    "    \n",
    "    # Make Predictions\n",
    "    output_ab = model(input_gray)\n",
    "    loss = criterion(output_ab, input_ab)\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # Apply optimizer\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Extract data from loss and accuracy\n",
    "    epoch_loss += loss.item()\n",
    "   \n",
    "  return epoch_loss/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(n_epochs, model, train_loader, val_loader, optimizer, criterion, save_images, model_name):\n",
    "\n",
    "  # Initialize validation loss\n",
    "  best_valid_loss = float('inf')\n",
    "\n",
    "  # Save output losses, accs\n",
    "  train_losses = []\n",
    "  valid_losses = []\n",
    "  \n",
    "\n",
    "  # Loop over epochs\n",
    "  for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Train\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    # Validation\n",
    "    valid_loss = evaluate(model, val_loader, criterion, save_images, epoch)\n",
    "    # Save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "      best_valid_loss = valid_loss\n",
    "      # Save model\n",
    "      torch.save(model.state_dict(), model_name)\n",
    "      \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch: {epoch+1}/{n_epochs} -- Epoch Time: {end_time-start_time:.2f} s\")\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"Train -- Loss: {train_loss:.3f}\")\n",
    "    print(f\"Val -- Loss: {valid_loss:.3f}\")\n",
    "\n",
    "    # Save\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "  return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-3d62cb1c-5924-4f7e-b229-275bd2748648",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1624906504986,
    "id": "R3fpxlZFsgwZ",
    "source_hash": "ac0ac087",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "train_transforms = transforms.Compose([transforms.Resize((80,80)),\n",
    "                                       transforms.RandomHorizontalFlip()])\n",
    "train_imagefolder = GrayscaleImageFolder(tr, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=64, shuffle=True)\n",
    "\n",
    "# Validation \n",
    "val_transforms = transforms.Compose([transforms.Resize((80,80))])\n",
    "val_imagefolder = GrayscaleImageFolder(te, val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00018-e8d7422b-cf03-4b1a-b209-49192e105505",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1624906509278,
    "id": "ZK1sJ0R2sgwd",
    "source_hash": "11433bd0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make folders and set parameters\n",
    "os.makedirs('./outputs/color', exist_ok=True)\n",
    "os.makedirs('./outputs/gray', exist_ok=True)\n",
    "\n",
    "save_images = True\n",
    "best_losses = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qRnVG9XydUiF"
   },
   "outputs": [],
   "source": [
    "#del model\n",
    "\n",
    "model = Colorization()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.SmoothL1Loss(beta = 0.75)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un-comment if you want to load a saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "peXphSe0Vx_M"
   },
   "outputs": [],
   "source": [
    "# pretrained = torch.load('./models/anim140.pth', map_location=lambda storage, loc: storage)\n",
    "# model.load_state_dict(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qdr-HCChEZiS",
    "outputId": "26324074-dfb9-4dfd-8d47-2cedf1708a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,572,288 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "proIP382hg-X"
   },
   "outputs": [],
   "source": [
    "# Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "  criterion = criterion.to('cuda')\n",
    "  model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "54PQnmDNG_N0",
    "outputId": "3120016c-d511-4867-e9f3-837aa2f4e06b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/10 -- Epoch Time: 71.62 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.036\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 72.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 72.51 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 75.35 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 76.81 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 76.51 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.007\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 74.86 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 74.83 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 75.37 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.062\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 75.56 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 75.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 78.22 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 75.05 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.011\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 73.68 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 6 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 5 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5/10 -- Epoch Time: 76.28 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 16 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6/10 -- Epoch Time: 77.45 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 74.26 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8/10 -- Epoch Time: 74.63 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.008\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 74.20 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.007\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 78.56 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 75.59 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.008\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 75.89 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.008\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 76.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 78.62 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 74.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 245 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6/10 -- Epoch Time: 73.78 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 73.81 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 74.03 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 78.51 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 82.91 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 85.06 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 83.96 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 85.41 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 83.86 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 82.52 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 74.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 75.75 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 83.80 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.008\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 84.31 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 85.17 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 85.31 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 84.18 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 84.94 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 85.56 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 84.57 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 84.76 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 84.40 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 207 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 13 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 70 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 503 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 485 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 32 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 3 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 318 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8/10 -- Epoch Time: 85.40 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 85.65 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 84.69 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 84.89 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 84.26 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 77.42 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 73.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.013\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 78.13 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 76.06 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 38 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 60 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 29 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 111 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 283 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 26 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 118 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7/10 -- Epoch Time: 76.13 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 75.67 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 76.15 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.007\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 74.17 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 17 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/10 -- Epoch Time: 70.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 73.32 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 69.77 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 70.64 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 70.10 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 70.75 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 71.27 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 74.62 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 73.77 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 75.09 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 78.20 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 75.84 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 75.42 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 75.40 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.008\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 75.53 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.004\n",
      "Val -- Loss: 0.010\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 74.29 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 74.72 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 77.51 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 76.45 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 78.57 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 11 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 8 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 540 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/10 -- Epoch Time: 77.75 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 74.66 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 76.26 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 74.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 78.04 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 76.56 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 76.06 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 75.86 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 81.17 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 80.23 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 78.82 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 93 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 14 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 43 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2/10 -- Epoch Time: 82.70 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 80.37 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 72.31 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 75.95 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 72.88 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 74.96 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 76.32 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 77.26 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 79.58 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.007\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 77.62 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 79.56 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 80.43 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4/10 -- Epoch Time: 78.71 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 77.13 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 76.88 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 76.76 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 34 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 35 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8/10 -- Epoch Time: 77.31 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 77.54 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.007\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 75.72 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 75.44 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 76.52 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 76.23 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 75.66 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 77.87 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 75.70 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 10 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
      "/home/morpheus/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/color/colorconv.py:1109: UserWarning: Color data out of range: Z < 0 in 18 pixels\n",
      "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7/10 -- Epoch Time: 76.21 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 73.33 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 76.33 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 75.30 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 76.68 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 75.98 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 75.12 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 72.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 78.58 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.001\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 75.73 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.003\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 75.86 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 76.79 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 75.98 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.001\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 75.30 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 1/10 -- Epoch Time: 75.85 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.001\n",
      "Val -- Loss: 0.005\n",
      "\n",
      "Epoch: 2/10 -- Epoch Time: 74.25 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.001\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 3/10 -- Epoch Time: 75.19 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 4/10 -- Epoch Time: 74.27 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 5/10 -- Epoch Time: 74.04 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.003\n",
      "\n",
      "Epoch: 6/10 -- Epoch Time: 75.51 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.001\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 7/10 -- Epoch Time: 72.97 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.006\n",
      "\n",
      "Epoch: 8/10 -- Epoch Time: 76.81 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.001\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 9/10 -- Epoch Time: 74.52 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n",
      "\n",
      "Epoch: 10/10 -- Epoch Time: 73.48 s\n",
      "---------------------------------\n",
      "Train -- Loss: 0.002\n",
      "Val -- Loss: 0.004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    N_EPOCHS = 10\n",
    "    model_name = f\"anim{N_EPOCHS*i}.pth\"\n",
    "    train_losses, valid_losses = model_training(N_EPOCHS, \n",
    "                                                model, \n",
    "                                                train_loader, \n",
    "                                                val_loader, \n",
    "                                                optimizer, \n",
    "                                                criterion,\n",
    "                                                save_images,\n",
    "                                                model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0H3iAkKJEg3Q"
   },
   "outputs": [],
   "source": [
    "out_transforms = transforms.Compose([transforms.Resize(120),\n",
    "                                     transforms.CenterCrop(100)])\n",
    "out_imagefolder = GrayscaleImageFolder('out/', val_transforms)\n",
    "out_loader = torch.utils.data.DataLoader(out_imagefolder, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "stq8snpjIJot",
    "outputId": "95b82fb1-5094-4a9d-d116-d43a979a7d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validate\n",
    "save_images = True\n",
    "with torch.no_grad():\n",
    "  evaluate(model, val_loader, criterion, save_images, epoch = 140)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "luka_good.ipynb",
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ec895ec4-c3f6-4c35-9156-b190a88c41e3",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
